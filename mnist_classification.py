# -*- coding: utf-8 -*-
"""MNIST Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13sBmWYCvz6Vaj1Io-T4cibGtaAxPVfmo
"""

import tensorflow
from tensorflow import keras
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Flatten

(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()

X_train.shape

y_train

import matplotlib.pyplot as plt
plt.imshow(X_train[1])

# Converting X_train and X_test to get values between 0 and 1 values
X_train = X_train/255
X_test = X_test/255

X_train[0]

model = Sequential()

model.add(Flatten(input_shape=(28, 28)))

model.add(Dense(128, activation='relu'))

model.add(Dense(32, activation='relu'))

# 10 nodes in Output layer because there are 10 classes 
model.add(Dense(10, activation='softmax'))

model.summary()

model.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics='accuracy')

from tensorflow.python import metrics
history = model.fit(X_train, y_train, epochs = 20, validation_split=0.2)
history

y_prob = model.predict(X_test)

y_pred = y_prob.argmax(axis=1)

from sklearn.metrics import accuracy_score
accuracy_score(y_test, y_pred)

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])

plt.imshow(X_test[1])

model.predict(X_test[1].reshape(1, 28, 28)).argmax(axis=1)

